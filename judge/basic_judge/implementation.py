from langchain_core.messages import SystemMessage
from pydantic import BaseModel, Field

from judge.judge_interface import IJudge
from prompts.judge_prompts import (JUDGE_USER_MESSAGE_PROMPT_TEMPLATE,
                                       JUDGE_RECOMMENDER_MESSAGE_PROMPT_TEMPLATE,
                                       JUDGE_USER_CONVERSATION_PROMPT_TEMPLATE,
                                       JUDGE_RECOMMENDER_CONVERSATION_PROMPT_TEMPLATE)


class UserMessageEvaluationScoreSet(BaseModel):
    clarity_score: int = Field(5, description="Score for clarity (1-10)")
    engagement_score: int = Field(5, description="Score for engagement (1-10)")
    coherence_with_context_score: int = Field(5, description="Score for coherence with context (1-10)")
    persona_alignment_score: int = Field(5, description="Score for persona alignment (1-10)")
    realism_score: int = Field(5, description="""
Score from (1-10) 1 being the worst and 10 being the best based on following criteria
Does the message seem to have been writen by the user? is it long detailed responses are
less realistic, being too aware of their preferences is (unless its in their personality) is
less realistic, also the phrases and language should reflect the review phrase and writing
style not like a text generated by highly correct grammar and sophisticated words)
        """)


class RecommenderMessageEvaluationScoreSet(BaseModel):
    relevance_score: int = Field(5, description="Score for relevance (1-10)")
    helpfulness_score: int = Field(5, description="Score for helpfulness (1-10)")
    coherence_with_context_score: int = Field(5, description="Score for coherence with context (1-10)")
    engagement_score: int = Field(5, description="Score for engagement (1-10)")
    detail_score: int = Field(5, description="Score for accurate details (1-10)"
                                             "Does the message provide needed information, or maybe accurate metrics"
                                             " or statistics if needed?")


class RecommenderConversationEvaluationScoreSet(BaseModel):
    suggestion_score: int = Field(5, description="""
Score from (1-10) 1 being the worst and 10 being the best based on following criteria
Are the suggestions good match for the costumer considering their persona and raw review and ignoring the user response?
If there is any mismatch between persona or review and the suggested car this harms the score e.g. budget mismatch etc..
    """)


class UserConversationEvaluationScoreSet(BaseModel):
    exploration_score: int = Field(5, description="""
Score from (1-10) 1 being the worst and 10 being the best based on following criteria
Buying a car is a big deal to humans and they tend to make sure that they are making the right decision and that they 
are choosing the right car among all cars, so if the user is persuaded easily and agrees to buy a car they do not 
reflect real users, how good is this user simulator at this?
    """)


class JudgeImplementation(IJudge):
    def __init__(self, llm):
        super().__init__()

        self.user_message_evaluator = llm.with_structured_output(UserMessageEvaluationScoreSet)
        self.recommender_message_evaluator = llm.with_structured_output(RecommenderMessageEvaluationScoreSet)
        self.user_conversation_evaluator = llm.with_structured_output(UserConversationEvaluationScoreSet)
        self.recommender_conversation_evaluator = llm.with_structured_output(RecommenderConversationEvaluationScoreSet)

    def _validate_interaction(self, interaction: dict) -> bool:
        if "role" not in interaction.keys():
            return False
        role = interaction.get("role")
        if role not in ["user", "assistant"]:
            return False

        if "content" not in interaction.keys():
            return False
        content = interaction.get("content")
        if not isinstance(content, str):
            return False

        return True

    def evaluate_user_simulation(self, persona: str, raw_review: str) -> dict:
        user_message_criteria = {
            "clarity": "Is the user's message clear and understandable within the context?",

            "engagement": "Does the user keep the conversation flowing and invite meaningful responses?",

            "coherence_with_context": "Is the user's message consistent with the earlier turns in conversation?",

            "persona_alignment": "Does the message reflect the user's stated persona, preferences, and writing style?",


            "realism": "Does the message seem to have been writen by the user? is it long detailed responses are "
                       "less realistic, being too aware of their preferences is (unless its in their personality) is "
                       "less realistic, also the phrases and language should reflect the review phrase and writing "
                       "style not like a text generated by highly correct grammar and sophisticated words",
        }
        user_conversation_criteria = {
            "exploration": """
Score from (1-10) 1 being the worst and 10 being the best based on following criteria
Buying a car is a big deal to humans and they tend to make sure that they are making the right decision and that they 
are choosing the right car among all cars, so if the user is persuaded easily and agrees to buy a car they do not 
reflect real users, how good is this user simulator at this? note that the user should have kept going with the 
questions in case he is not sure that the final suggestion is the best match for him
"""
        }
        conversation = self.get_conversation()
        scores_dict = {
            "clarity": [],
            "engagement": [],
            "coherence_with_context": [],
            "persona_alignment": []
        }
        for turn_idx, turn in enumerate(conversation):
            if turn["role"] != "user":
                continue

            # Build conversation context so far
            context_up_to_now = conversation[:turn_idx]  # all prior turns
            context_text = "\n".join(f"{t['role'].upper()}: {t['content']}" for t in context_up_to_now)

            # This user's message
            user_message = turn["content"]

            # Evaluate using the chain
            evaluation_prompt = JUDGE_USER_MESSAGE_PROMPT_TEMPLATE.format(
                persona=persona,
                review=raw_review,
                context=context_text,
                message=user_message,
                criteria=user_message_criteria
            )
            scores: UserMessageEvaluationScoreSet = self.user_message_evaluator.invoke([SystemMessage(evaluation_prompt)])

            # Append scores to dict
            scores_dict["clarity"].append(scores.clarity_score)
            scores_dict["engagement"].append(scores.engagement_score)
            scores_dict["coherence_with_context"].append(scores.coherence_with_context_score)
            scores_dict["persona_alignment"].append(scores.persona_alignment_score)

        conversation_str = "\n".join(f"{t['role'].upper()}: {t['content']}" for t in conversation)
        user_conversation_scores = self.user_conversation_evaluator.invoke([
            SystemMessage(
                JUDGE_USER_CONVERSATION_PROMPT_TEMPLATE.format(
                    persona=persona,
                    review=raw_review,
                    conversation=conversation_str,
                    criteria=user_conversation_criteria
                )
            )
        ])
        scores_dict["conversation_level"] = {
            "exploration_quality": user_conversation_scores.exploration_score
        }
        return scores_dict

    def evaluate_recommender(self) -> dict:
        recommender_message_criteria = {
            "relevance": "Is the assistant's response relevant to the user's message?",
            "helpfulness": "Does the response provide useful recommendations or information?",
            "coherence_with_context": "Is the response consistent with the earlier conversation? the response should "
                                      "consider all the user preferences we have gathered and should not ignore any of"
                                      " them",
            "engagement": "Does the response encourage further interaction?",
            "detail_score": "Does the message provide needed information, or maybe accurate metrics or statistics if "
                            "needed?"
        }
        recommender_conversation_criteria = {
            "suggestion": """
Score from (1-10) 1 being the worst and 10 being the best based on following criteria
Are the suggestions good match for the costumer considering their persona and raw review and ignoring the user response?
If there is any mismatch between persona or review and the suggested car this harms the score e.g. budget mismatch etc..
"""
        }
        conversation = self.get_conversation()
        scores_dict = {
            "relevance": [],
            "helpfulness": [],
            "coherence_with_context": [],
            "engagement": []
        }
        for turn_idx, turn in enumerate(conversation):
            if turn["role"] != "assistant":
                continue

            # Build conversation context so far
            context_up_to_now = conversation[:turn_idx]  # all prior turns
            context_text = "\n".join(f"{t['role'].upper()}: {t['content']}" for t in context_up_to_now)

            # This recommender's message
            assistant_message = turn["content"]

            # Evaluate using the chain
            evaluation_prompt = JUDGE_RECOMMENDER_MESSAGE_PROMPT_TEMPLATE.format(
                context=context_text,
                message=assistant_message,
                criteria=recommender_message_criteria
            )
            scores: RecommenderMessageEvaluationScoreSet = self.recommender_message_evaluator.invoke([SystemMessage(evaluation_prompt)])

            # Append scores to dict
            scores_dict["relevance"].append(scores.relevance_score)
            scores_dict["helpfulness"].append(scores.helpfulness_score)
            scores_dict["coherence_with_context"].append(scores.coherence_with_context_score)
            scores_dict["engagement"].append(scores.engagement_score)

        conversation_str = "\n".join(f"{t['role'].upper()}: {t['content']}" for t in conversation)
        recommender_conversation_scores = self.recommender_conversation_evaluator.invoke([
            SystemMessage(
                JUDGE_RECOMMENDER_CONVERSATION_PROMPT_TEMPLATE.format(
                    conversation=conversation_str,
                    criteria=recommender_conversation_criteria
                )
            )
        ])
        scores_dict["conversation_level"] = {
            "suggestion_quality": recommender_conversation_scores.suggestion_score
        }
        return scores_dict
